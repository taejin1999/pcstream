\section{Introduction}
\label{sec:intro}
Multi-streamed SSDs provide a special mechanism,
called streams, for a host system to prevent data with different lifetimes 
from being mixed into the same block~\cite{T10, MultiStream}.
When the host system maps two data $D_1$ and $D_2$ to 
different streams $S_1$ and $S_2$, a multi-streamed SSD guarantees that 
$D_1$ and $D_2$ are placed to different blocks.   
Since streams, when properly managed, can be very effective in minimizing 
the copy cost of garbage collection, they
can significantly improve both the performance and lifetime of 
flash-based SSDs~\cite{MultiStream, FStream, AutoStream, Level}.

In order to achieve high performance on multi-streamed SSDs, data with similar 
{\it future} update times~\cite{PCHa}
should be allocated 
to the same stream, so that the copy cost of garbage collection can be minimized.
However, since it is difficult to know the future update times {\it a priori} when they are written,
stream allocation decisions are often {\it manually} made by programmers based on their expertise (or experience) 
on the application~\cite{MultiStream} or the file system~\cite{FStream}.  
Furthermore, these manual techniques assume a fixed number of 
streams (i.e., a specific SSD).   
When an SSD has a smaller number of streams, stream allocation decisions should be changed.
In this paper, our goal is to develop 
a {\it fully automatic} technique for managing streams 
which is applicable for {\it any} multi-streamed SSD
\footnote{The main difference among different multi-streamed 
SSDs is the maximum number of streams supported.  
For example, the SSD used in FStream~\cite{FStream} has 9 streams 
while the SSD used in AutoStream~\cite{AutoStream} has 16 streams.}.

To the best of our knowledge, AutoStream~\cite{AutoStream} is the only automatic 
stream management technique
without additional manual work.  
However, since AutoStream predicts data lifetimes using the update frequency 
of the logical block address (LBA), it does not work well with modern append-only workloads 
such as RocksDB~\cite{RocksDB} or Cassandra~\cite{Cassandra}.  
Unlike conventional update workloads where data written to the same LBAs 
often show a strong update locality, 
append-only workloads make it impossible to predict data lifetimes 
from the LBA characteristics (such as access frequency or access patterns).  
For example, as shown in Figure~\ref{fig:lba_lifetime}(b), 
data written to a fixed LBA range over times in RocksDB 
show widely varying data lifetimes, 
thus making it difficult to allocate streams based on LBA characteristics.

In this paper, we propose a fully automatic stream management technique, called {\sf PCStream}, 
for multi-streamed SSDs based on program contexts (PCs).
Since the key motivation behind {\sf PCStream} was 
that data lifetimes should be estimated at a higher abstraction level than LBAs, 
{\sf PCStream} employed a write program context\footnote{Since we are interested in write-related 
system calls such as write() and writev() in the Linux kernel, 
we call their related program contexts as 
{\it write program contexts.} In the rest of the paper, we use 
{\it program contexts} interchangeably with {\it write program contexts}.}  
as a main unit for managing streams.   
A program context~\cite{PC}, which represents a particular execution phase of a program, 
is known to be an effective hint in separating data with different lifetimes~\cite{PCHa}.  
(That is, the lifetime of data written by the same program context tends to be very similar.)   
{\sf PCStream} automatically maps an identified program context to a stream.  
Since program contexts can be computed during the run time, 
{\sf PCStream} does not need any manual work.   
In order to handle append-only workloads, 
{\sf PCStream} extended the definition of the data lifetime 
so that the effect of the TRIM command~\cite{10} can be accounted for. 

Although most program contexts show that their data lifetimes are 
distributed with small variances, we observed a few outliers 
whose data lifetimes have rather large variances.
In {\sf PCStream}, 
when such a PC {\it pID} is observed (which was mapped to a stream {\it sID}), 
the long-lived data of {\it pID} are moved to the substream of {\it sID}
during garbage collection.  
The substream prevents the long-lived data of the stream {\it sID} 
from being mixed with future short-lived data of the stream {\it sID}.

In order to evaluate the effectiveness of PCStream, we have implemented PCStream 
in the Linux kernel (v. 4.5) and measured write amplification factor (WAF) values 
using RocksDB on a Samsung PM963 SSD (which have 8 streams).  

Our experimental results show that {\sf PCStream} is quite effective.  
It reduced the average WAF by XXX\% over AutoStream.  
Furthermore, PCStream outperformed {\it even} the existing manual technique~\cite{MultiStream} 
by reducing the average WAF by XXX\%.

The rest of this paper is organized as follows. 
We explain the key motivations behind {\sf PCStream} in Section 2. 
Section 3 describes 
the design and implementation of {\sf PCStream}.
The experimental results are shown in Section 4. 
Finally, we conclude in Section 5 with a summary and future work. 

